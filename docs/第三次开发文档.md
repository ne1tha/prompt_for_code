# 开发日志 #3: 动态嵌入、API 修复与智能分片

**日期:** 2025年10月21日

**概览:**
本次迭代是项目的一个重要里程碑。我们成功地将嵌入模型配置动态化，使其能够接入（并传递维度参数到）任何与 OpenAI 兼容的 API（例如通义千问 DashScope）。同时，我们修复了 API 层一个严重的 Pydantic 序列化 Bug，并极大地增强了 Qdrant 集合处理的鲁棒性和文档分片（Chunking）的智能性。

---

## 1. 动态嵌入模型集成 (Pipeline & Service)

为了支持使用不同维度和 API 端点的嵌入模型（如 `text-embedding-v3`），我们对嵌入流程进行了重大重构。

* **`model.py` (Schema):**
    * **[修复]** 在 `ModelBase`、`ModelUpdate` Pydantic 模式中重新添加了 `dimensions` 字段。这是后续所有流程正常工作的关键前提。

* **`ingestion_pipeline.py` (核心管道):**
    * `run_ingestion_pipeline` 函数签名变更。它不再接收 `embedding_model_id`，而是接收一个包含所有模型详情的字典 `embedding_model_details: Dict[str, Any]`。这使得管道本身与数据库解耦。
    * 新增 `get_embeddings_from_api` 异步函数。此函数使用 `AsyncOpenAI` 客户端，并被配置为可以调用任意 `base_url`（即 `endpoint_url`）。
    * **[关键]** 在调用嵌入 API 时，`get_embeddings_from_api` 现在会**显式传递 `dimensions` 参数**。这对于 v3/v4 系列模型至关重要。
    * 管道现在从传入的 `embedding_model_details` 字典中提取 `endpoint_url`, `api_key`, `name`, 和 `dimensions`，并在启动时进行验证。

* **`kb_service.py` (服务层):**
    * `start_kb_parsing` 函数现在负责从数据库加载 `db_model`。
    * **[关键]** 它现在会严格验证模型：必须是 `embedding` 类型，并且必须设置了 `dimensions`、`endpoint_url` 和 `name`。
    * 在触发后台任务时，它会构建 `embedding_model_details` 字典，将模型的完整信息（包括 `dimensions`）传递给 `run_ingestion_pipeline`。

## 2. API 层重大修复 (Router & Schemas)

我们解决了先前版本中 API 响应（尤其是 `upload` 和 `start_parsing`）存在的严重 Pydantic 转换和序列化问题。

* **`knowledgebase.py` (Schema):**
    * **[修复]** 彻底修复了 `KnowledgeBase` 响应模式中 `snake_case` (Python) 到 `camelCase` (JSON) 的转换问题。
    * 移除了过时的 `alias_generator`。
    * 使用 `Field(serialization_alias=...)` 为 `parsing_state` -> `parsingState`、`source_file_path` -> `sourceFilePath` 和 `updated_at` -> `updatedAt` 提供了标准、可靠的别名。

* **`knowledgebases.py` (Router):**
    * **[修复]** 引入了一个新的辅助函数 `convert_sqlalchemy_to_pydantic`。
    * **[关键]** `upload_kb_file` 和 `start_parsing` 端点现在**显式调用此转换器**，以确保从 Service 层返回的 SQLAlchemy ORM 对象被正确、安全地转换为 Pydantic 响应模型 (`KnowledgeBaseSchema`)。这解决了之前返回数据结构不匹配或序列化失败的 Bug。
    * `start_parsing` 端点现在也正确地注入了 `BackgroundTasks` 依赖，并将其传递给 `kb_service.start_kb_parsing`，从而成功启动后台摄取任务。

## 3. 核心服务层：Qdrant 鲁棒性增强

为了防止在更换嵌入模型（导致维度变化）时发生向量错误，我们重写了 Qdrant 集合的准备逻辑。

* **`kb_service.py` (`start_kb_parsing`):**
    * **[关键增强]** 在开始解析前，Qdrant 准备逻辑现在遵循以下稳健流程：
        1.  尝试 `qdrant.get_collection` 获取现有集合。
        2.  **如果存在：** 它会智能地检查 `coll_info.config.params.vectors` 来解析出当前集合的向量维度（`size`），无论它是默认向量还是命名向量。
        3.  **维度比较：** 将 *当前维度* 与所选 *新模型* 的 `required_dimension` 进行比较。
        4.  **如果维度不匹配：** 会自动调用 `qdrant.recreate_collection`，使用新维度重建集合。
        5.  **如果不存在：** 则按预期调用 `qdrant.create_collection` 创建新集合。
    * 此项改动确保了知识库始终使用与其配置模型相匹配的向量维度，消除了因模型切换导致的摄取失败。

## 4. 智能文档分片 (Ingestion Pipeline)

为了提高代码类知识库的检索质量，我们引入了动态分片器（Dynamic Splitter）。

* **`ingestion_pipeline.py` (Stage 3):**
    * 管道现在会检查每个待处理文档的文件扩展名（如 `.py`, `.js`, `.java`, `.rs`, `.c`, `.cpp` 等）。
    * **如果是已知代码文件：** 使用 `CodeSplitter`，它基于代码的语法结构按行（`chunk_lines`）进行切分，更适合代码块。
    * **如果是其他文件（或未知）：** 回退到标准的 `SentenceSplitter`，它按 `chunk_size`（字符数）进行切分。
    * 此项改进确保了代码片段和普通文本都能以最合适的方式被索引。